{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "for dataset in ['iwslt14', 'multi30k']:\n",
    "    logs = pkl.load(open('data/{dataset}_logs.pkl'.format(dataset=dataset), 'rb'))\n",
    "\n",
    "    num_datapoints = len(logs['sequences'])\n",
    "\n",
    "    iterations = logs['normal_A'].keys()\n",
    "    dicts = logs['sequences']\n",
    "    for key in logs:\n",
    "        if key == 'sequences':\n",
    "            continue\n",
    "        for iteration in iterations:\n",
    "            for datapoint_idx in range(num_datapoints):\n",
    "                dicts[datapoint_idx][(key, iteration, 'alpha')] = logs[key][iteration][datapoint_idx]['alpha']\n",
    "                dicts[datapoint_idx][(key, iteration, 'beta')] = logs[key][iteration][datapoint_idx]['beta']\n",
    "                dicts[datapoint_idx]['split'] = logs[key][iteration][datapoint_idx]['split']\n",
    "    pkl.dump(dicts, open('data/{dataset}_logs_rz.pkl'.format(dataset=dataset), 'wb'))\n",
    "    \"\"\"\n",
    "from utils import *\n",
    "\n",
    "def max_acc_iter(name, metas):\n",
    "    max_acc = -1.0\n",
    "    max_acc_iter = None\n",
    "    for key_ in metas:\n",
    "        print(name, key_)\n",
    "        if key_[0] == name and 'val' in key_[2]:\n",
    "            if metas[key_] > max_acc:\n",
    "                max_acc = metas[key_]\n",
    "                max_acc_iter = key_[1]\n",
    "    return max_acc_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'news_commentary_v14_en_nl'\n",
    "dat = pkl.load(open('outputs/{dataset}_logs.pkl'.format(dataset=dataset), 'rb'))\n",
    "all_dicts = dat['data']\n",
    "subset = 'val'\n",
    "dicts = [d for d in all_dicts if d['split'] == 'val']\n",
    "iterations = sorted(list(set([key[1] for key in dat['metas']])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal_A ('normal_A', 10000, 'val_acc')\n",
      "normal_A ('normal_A', 10000, 'val_perplexity')\n",
      "normal_A ('normal_A', 10000, 'train_acc')\n",
      "normal_A ('normal_A', 10000, 'train_perplexity')\n",
      "normal_A ('normal_A', 50000, 'val_acc')\n",
      "normal_A ('normal_A', 50000, 'val_perplexity')\n",
      "normal_A ('normal_A', 50000, 'train_acc')\n",
      "normal_A ('normal_A', 50000, 'train_perplexity')\n",
      "normal_A ('normal_A', 98000, 'val_acc')\n",
      "normal_A ('normal_A', 98000, 'val_perplexity')\n",
      "normal_A ('normal_A', 98000, 'train_acc')\n",
      "normal_A ('normal_A', 98000, 'train_perplexity')\n",
      "normal_B ('normal_A', 10000, 'val_acc')\n",
      "normal_B ('normal_A', 10000, 'val_perplexity')\n",
      "normal_B ('normal_A', 10000, 'train_acc')\n",
      "normal_B ('normal_A', 10000, 'train_perplexity')\n",
      "normal_B ('normal_A', 50000, 'val_acc')\n",
      "normal_B ('normal_A', 50000, 'val_perplexity')\n",
      "normal_B ('normal_A', 50000, 'train_acc')\n",
      "normal_B ('normal_A', 50000, 'train_perplexity')\n",
      "normal_B ('normal_A', 98000, 'val_acc')\n",
      "normal_B ('normal_A', 98000, 'val_perplexity')\n",
      "normal_B ('normal_A', 98000, 'train_acc')\n",
      "normal_B ('normal_A', 98000, 'train_perplexity')\n",
      "uniform ('normal_A', 10000, 'val_acc')\n",
      "uniform ('normal_A', 10000, 'val_perplexity')\n",
      "uniform ('normal_A', 10000, 'train_acc')\n",
      "uniform ('normal_A', 10000, 'train_perplexity')\n",
      "uniform ('normal_A', 50000, 'val_acc')\n",
      "uniform ('normal_A', 50000, 'val_perplexity')\n",
      "uniform ('normal_A', 50000, 'train_acc')\n",
      "uniform ('normal_A', 50000, 'train_perplexity')\n",
      "uniform ('normal_A', 98000, 'val_acc')\n",
      "uniform ('normal_A', 98000, 'val_perplexity')\n",
      "uniform ('normal_A', 98000, 'train_acc')\n",
      "uniform ('normal_A', 98000, 'train_perplexity')\n"
     ]
    }
   ],
   "source": [
    "from utils import TopKMatch, TopPercentMatch, SpearmanRankCorr\n",
    "metrics = [TopKMatch(k=1), TopKMatch(k=3), TopKMatch(k=5), TopPercentMatch(p=5)]\n",
    "normalA_iter = max_acc_iter('normal_A', dat['metas'])\n",
    "normalB_iter = max_acc_iter('normal_B', dat['metas'])\n",
    "uniform_iter = max_acc_iter('uniform', dat['metas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('normal_A', 10000, 'alpha') ('normal_B', None, 'beta')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "('normal_B', None, 'beta')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-7d08263ad98f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_corr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/current_projects/NLP_research/AttentionResearch/AttentionDynamics/translation/utils.py\u001b[0m in \u001b[0;36meval_corr\u001b[0;34m(self, dicts, key1, key2)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# for each datapoints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0marr1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;31m# for each target word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ('normal_B', None, 'beta')"
     ]
    }
   ],
   "source": [
    "# metrics.append(SpearmanRankCorr()) comment out because this takes a lot of time to evaluate\n",
    "key1, key2 = ('normal_A', normalA_iter, 'alpha'), ('normal_B', normalB_iter, 'beta')\n",
    "print(key1, key2)\n",
    "for metric in metrics:\n",
    "    print(metric.eval_corr(dicts, key1, key2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('normal_A', inf, 'alpha') ('uniform', inf, 'beta')\n",
      "{'name': 'top 1 match', 'correlation': 0.2826946847960445, 'baseline': 0.06415327564894932}\n",
      "{'name': 'top 3 match', 'correlation': 0.4283683559950556, 'baseline': 0.17441285537700865}\n",
      "{'name': 'top 5 match', 'correlation': 0.519406674907293, 'baseline': 0.2915327564894932}\n",
      "{'name': 'top 5% match', 'correlation': 0.31087762669962915, 'baseline': 0.07836835599505562}\n"
     ]
    }
   ],
   "source": [
    "key1, key2 = ('normal_A', iterations[-1], 'alpha'), ('uniform', iterations[-1], 'beta')\n",
    "print(key1, key2)\n",
    "for metric in metrics:\n",
    "    print(metric.eval_corr(dicts, key1, key2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('uniform', inf, 'beta') embed256_beta\n",
      "{'name': 'top 1 match', 'correlation': 0.31946847960444996, 'baseline': 0.05562422744128554}\n",
      "{'name': 'top 3 match', 'correlation': 0.49128553770086525, 'baseline': 0.16668726823238567}\n",
      "{'name': 'top 5 match', 'correlation': 0.619406674907293, 'baseline': 0.29208899876390604}\n",
      "{'name': 'top 5% match', 'correlation': 0.35018541409147097, 'baseline': 0.07669962917181705}\n"
     ]
    }
   ],
   "source": [
    "key1, key2 = ('uniform', iterations[-1], 'beta'), 'embed256_beta'\n",
    "print(key1, key2)\n",
    "for metric in metrics:\n",
    "    print(metric.eval_corr(dicts, key1, key2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('uniform', inf, 'beta') IBM_beta\n",
      "{'name': 'top 1 match', 'correlation': 0.17626699629171816, 'baseline': 0.10618046971569839}\n",
      "{'name': 'top 3 match', 'correlation': 0.22632880098887515, 'baseline': 0.17132262051915945}\n",
      "{'name': 'top 5 match', 'correlation': 0.4700865265760198, 'baseline': 0.29054388133498144}\n",
      "{'name': 'top 5% match', 'correlation': 0.180778739184178, 'baseline': 0.11897404202719407}\n"
     ]
    }
   ],
   "source": [
    "key1, key2 = ('uniform', iterations[-1], 'beta'), 'IBM_beta'\n",
    "print(key1, key2)\n",
    "for metric in metrics:\n",
    "    print(metric.eval_corr(dicts, key1, key2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
