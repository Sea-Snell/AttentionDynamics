{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "for dataset in ['iwslt14', 'multi30k']:\n",
    "    logs = pkl.load(open('data/{dataset}_logs.pkl'.format(dataset=dataset), 'rb'))\n",
    "\n",
    "    num_datapoints = len(logs['sequences'])\n",
    "\n",
    "    iterations = logs['normal_A'].keys()\n",
    "    dicts = logs['sequences']\n",
    "    for key in logs:\n",
    "        if key == 'sequences':\n",
    "            continue\n",
    "        for iteration in iterations:\n",
    "            for datapoint_idx in range(num_datapoints):\n",
    "                dicts[datapoint_idx][(key, iteration, 'alpha')] = logs[key][iteration][datapoint_idx]['alpha']\n",
    "                dicts[datapoint_idx][(key, iteration, 'beta')] = logs[key][iteration][datapoint_idx]['beta']\n",
    "                dicts[datapoint_idx]['split'] = logs[key][iteration][datapoint_idx]['split']\n",
    "    pkl.dump(dicts, open('data/{dataset}_logs_rz.pkl'.format(dataset=dataset), 'wb'))\n",
    "    \"\"\"\n",
    "from utils import *\n",
    "\n",
    "def max_acc_iter(name, metas):\n",
    "    max_acc = -1.0\n",
    "    max_acc_iter = None\n",
    "    for key_ in metas:\n",
    "        if key_[0] == name and 'test' in key_[2]:\n",
    "            if metas[key_] > max_acc:\n",
    "                max_acc = metas[key_]\n",
    "                max_acc_iter = key_[1]\n",
    "    return max_acc_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'SMS'\n",
    "dat = pkl.load(open('outputs/{dataset}_logs.pkl'.format(dataset=dataset), 'rb'))\n",
    "all_dicts = dat['data']\n",
    "subset = 'val'\n",
    "dicts = [d for d in all_dicts if d['split'] == subset]\n",
    "iterations = sorted(list(set([key[1] for key in dat['metas']])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import TopKMatch, TopPercentMatch, SpearmanRankCorr\n",
    "metrics = [TopKMatch(k=1), TopKMatch(k=3), TopKMatch(k=5), TopPercentMatch(p=5)]\n",
    "normalA_iter = max_acc_iter('normal_A', dat['metas'])\n",
    "normalB_iter = max_acc_iter('normal_B', dat['metas'])\n",
    "uniform_iter = max_acc_iter('uniform', dat['metas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('normal_A', 1500, 'alpha') ('normal_B', 500, 'beta')\n",
      "{'name': 'top 1 match', 'correlation': 0.06557377049180328, 'baseline': 0.07280617164898746}\n",
      "{'name': 'top 3 match', 'correlation': 0.14368370298939248, 'baseline': 0.23722275795564127}\n",
      "{'name': 'top 5 match', 'correlation': 0.2391513982642237, 'baseline': 0.37849566055930567}\n",
      "{'name': 'top 5% match', 'correlation': 0.09450337512054002, 'baseline': 0.09209257473481196}\n",
      "('normal_A', 1500, 'alpha') ('normal_B', 1500, 'beta')\n",
      "{'name': 'top 1 match', 'correlation': 0.06943105110896818, 'baseline': 0.07521697203471553}\n",
      "{'name': 'top 3 match', 'correlation': 0.13886210221793635, 'baseline': 0.23577627772420442}\n",
      "{'name': 'top 5 match', 'correlation': 0.22806171648987464, 'baseline': 0.3780135004821601}\n",
      "{'name': 'top 5% match', 'correlation': 0.0935390549662488, 'baseline': 0.0863066538090646}\n",
      "('normal_A', 1500, 'alpha') ('normal_B', 3000, 'beta')\n",
      "{'name': 'top 1 match', 'correlation': 0.07232401157184185, 'baseline': 0.07280617164898746}\n",
      "{'name': 'top 3 match', 'correlation': 0.13404050144648022, 'baseline': 0.2459016393442623}\n",
      "{'name': 'top 5 match', 'correlation': 0.22034715525554485, 'baseline': 0.3678881388621022}\n",
      "{'name': 'top 5% match', 'correlation': 0.09691417550626807, 'baseline': 0.08196721311475409}\n",
      "('normal_A', 1500, 'alpha') ('normal_B', 3999, 'beta')\n",
      "{'name': 'top 1 match', 'correlation': 0.07087753134040502, 'baseline': 0.07714561234329798}\n",
      "{'name': 'top 3 match', 'correlation': 0.13066538090646093, 'baseline': 0.23191899710703953}\n",
      "{'name': 'top 5 match', 'correlation': 0.21552555448408872, 'baseline': 0.3770491803278688}\n",
      "{'name': 'top 5% match', 'correlation': 0.09643201542912247, 'baseline': 0.0863066538090646}\n"
     ]
    }
   ],
   "source": [
    "# metrics.append(SpearmanRankCorr()) comment out because this takes a lot of time to evaluate\n",
    "for iter_ in iterations:\n",
    "    key1, key2 = ('normal_A', normalA_iter, 'alpha'), ('normal_B', iter_, 'beta')\n",
    "    print(key1, key2)\n",
    "    for metric in metrics:\n",
    "        print(metric.eval_corr(dicts, key1, key2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('normal_A', 1500, 'alpha') ('uniform', 500, 'beta')\n",
      "{'name': 'top 1 match', 'correlation': 0.0048216007714561235, 'baseline': 0.07762777242044358}\n",
      "{'name': 'top 3 match', 'correlation': 0.027965284474445518, 'baseline': 0.2266152362584378}\n",
      "{'name': 'top 5 match', 'correlation': 0.06750241080038573, 'baseline': 0.3799421407907425}\n",
      "{'name': 'top 5% match', 'correlation': 0.008678881388621022, 'baseline': 0.09257473481195758}\n",
      "('normal_A', 1500, 'alpha') ('uniform', 1500, 'beta')\n",
      "{'name': 'top 1 match', 'correlation': 0.009643201542912247, 'baseline': 0.07666345226615236}\n",
      "{'name': 'top 3 match', 'correlation': 0.03326904532304725, 'baseline': 0.2304725168756027}\n",
      "{'name': 'top 5 match', 'correlation': 0.08486017357762778, 'baseline': 0.39344262295081966}\n",
      "{'name': 'top 5% match', 'correlation': 0.015429122468659595, 'baseline': 0.0935390549662488}\n",
      "('normal_A', 1500, 'alpha') ('uniform', 3000, 'beta')\n",
      "{'name': 'top 1 match', 'correlation': 0.010607521697203472, 'baseline': 0.085824493731919}\n",
      "{'name': 'top 3 match', 'correlation': 0.03567984570877531, 'baseline': 0.23191899710703953}\n",
      "{'name': 'top 5 match', 'correlation': 0.08727097396335583, 'baseline': 0.3746383799421408}\n",
      "{'name': 'top 5% match', 'correlation': 0.01446480231436837, 'baseline': 0.09932497589199614}\n",
      "('normal_A', 1500, 'alpha') ('uniform', 3999, 'beta')\n",
      "{'name': 'top 1 match', 'correlation': 0.010607521697203472, 'baseline': 0.07714561234329798}\n",
      "{'name': 'top 3 match', 'correlation': 0.037608486017357765, 'baseline': 0.23529411764705882}\n",
      "{'name': 'top 5 match', 'correlation': 0.08823529411764706, 'baseline': 0.3799421407907425}\n",
      "{'name': 'top 5% match', 'correlation': 0.016875602700096432, 'baseline': 0.09643201542912247}\n"
     ]
    }
   ],
   "source": [
    "for iter_ in iterations:\n",
    "    key1, key2 = ('normal_A', normalA_iter, 'alpha'), ('uniform', iter_, 'beta')\n",
    "    print(key1, key2)\n",
    "    for metric in metrics:\n",
    "        print(metric.eval_corr(dicts, key1, key2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('uniform', 500, 'beta') logistics_beta\n",
      "{'name': 'top 1 match', 'correlation': 0.3037608486017358, 'baseline': 0.11137897782063645}\n",
      "{'name': 'top 3 match', 'correlation': 0.5419479267116682, 'baseline': 0.25650916104146576}\n",
      "{'name': 'top 5 match', 'correlation': 0.7000964320154291, 'baseline': 0.3919961427193828}\n",
      "{'name': 'top 5% match', 'correlation': 0.3254580520732883, 'baseline': 0.11089681774349083}\n",
      "('uniform', 1500, 'beta') logistics_beta\n",
      "{'name': 'top 1 match', 'correlation': 0.23674059787849566, 'baseline': 0.09980713596914176}\n",
      "{'name': 'top 3 match', 'correlation': 0.437801350048216, 'baseline': 0.24975891996142718}\n",
      "{'name': 'top 5 match', 'correlation': 0.5998071359691417, 'baseline': 0.390549662487946}\n",
      "{'name': 'top 5% match', 'correlation': 0.24686595949855353, 'baseline': 0.10125361620057859}\n",
      "('uniform', 3000, 'beta') logistics_beta\n",
      "{'name': 'top 1 match', 'correlation': 0.23143683702989393, 'baseline': 0.09112825458052073}\n",
      "{'name': 'top 3 match', 'correlation': 0.4296046287367406, 'baseline': 0.24059787849566056}\n",
      "{'name': 'top 5 match', 'correlation': 0.5964320154291225, 'baseline': 0.4021215043394407}\n",
      "{'name': 'top 5% match', 'correlation': 0.2415621986499518, 'baseline': 0.10221793635486982}\n",
      "('uniform', 3999, 'beta') logistics_beta\n",
      "{'name': 'top 1 match', 'correlation': 0.22372227579556414, 'baseline': 0.10270009643201543}\n",
      "{'name': 'top 3 match', 'correlation': 0.4218900675024108, 'baseline': 0.25940212150433944}\n",
      "{'name': 'top 5 match', 'correlation': 0.5891996142719382, 'baseline': 0.41128254580520734}\n",
      "{'name': 'top 5% match', 'correlation': 0.23336547733847637, 'baseline': 0.12054001928640308}\n"
     ]
    }
   ],
   "source": [
    "for iter_ in iterations:\n",
    "    key1, key2 = ('uniform', iter_, 'beta'), 'logistics_beta'\n",
    "    print(key1, key2)\n",
    "    for metric in metrics:\n",
    "        print(metric.eval_corr(dicts, key1, key2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
