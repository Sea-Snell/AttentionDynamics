{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "for dataset in ['iwslt14', 'multi30k']:\n",
    "    logs = pkl.load(open('data/{dataset}_logs.pkl'.format(dataset=dataset), 'rb'))\n",
    "\n",
    "    num_datapoints = len(logs['sequences'])\n",
    "\n",
    "    iterations = logs['normal_A'].keys()\n",
    "    dicts = logs['sequences']\n",
    "    for key in logs:\n",
    "        if key == 'sequences':\n",
    "            continue\n",
    "        for iteration in iterations:\n",
    "            for datapoint_idx in range(num_datapoints):\n",
    "                dicts[datapoint_idx][(key, iteration, 'alpha')] = logs[key][iteration][datapoint_idx]['alpha']\n",
    "                dicts[datapoint_idx][(key, iteration, 'beta')] = logs[key][iteration][datapoint_idx]['beta']\n",
    "                dicts[datapoint_idx]['split'] = logs[key][iteration][datapoint_idx]['split']\n",
    "    pkl.dump(dicts, open('data/{dataset}_logs_rz.pkl'.format(dataset=dataset), 'wb'))\n",
    "    \"\"\"\n",
    "from utils import *\n",
    "\n",
    "def max_acc_iter(name, metas):\n",
    "    max_acc = -1.0\n",
    "    max_acc_iter = None\n",
    "    for key_ in metas:\n",
    "        if key_[0] == name and 'val' in key_[2]:\n",
    "            if metas[key_] > max_acc:\n",
    "                max_acc = metas[key_]\n",
    "                max_acc_iter = key_[1]\n",
    "    return max_acc_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'news_commentary_v14_en_nl'\n",
    "dat = pkl.load(open('outputs/{dataset}_logs.pkl'.format(dataset=dataset), 'rb'))\n",
    "all_dicts = dat['data']\n",
    "subset = 'val'\n",
    "dicts = [d for d in all_dicts if d['split'] == 'val']\n",
    "iterations = sorted(list(set([key[1] for key in dat['metas']])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import TopKMatch, TopPercentMatch, SpearmanRankCorr\n",
    "metrics = [TopKMatch(k=1), TopKMatch(k=3), TopKMatch(k=5), TopPercentMatch(p=5)]\n",
    "normalA_iter = max_acc_iter('normal_A', dat['metas'])\n",
    "normalB_iter = max_acc_iter('normal_B', dat['metas'])\n",
    "uniform_iter = max_acc_iter('uniform', dat['metas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('normal_A', 98000, 'alpha') ('normal_B', 98000, 'beta')\n",
      "{'name': 'top 1 match', 'correlation': 0.4906809735378769, 'baseline': 0.029517236240347983}\n",
      "{'name': 'top 3 match', 'correlation': 0.630424455807975, 'baseline': 0.08793696034872998}\n",
      "{'name': 'top 5 match', 'correlation': 0.6835303322435521, 'baseline': 0.1448337850802433}\n",
      "{'name': 'top 5% match', 'correlation': 0.6016337403712707, 'baseline': 0.06422257616825476}\n"
     ]
    }
   ],
   "source": [
    "# metrics.append(SpearmanRankCorr()) comment out because this takes a lot of time to evaluate\n",
    "key1, key2 = ('normal_A', normalA_iter, 'alpha'), ('normal_B', normalB_iter, 'beta')\n",
    "print(key1, key2)\n",
    "for metric in metrics:\n",
    "    print(metric.eval_corr(dicts, key1, key2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('normal_A', 98000, 'alpha') ('uniform', 98000, 'beta')\n",
      "{'name': 'top 1 match', 'correlation': 0.26383882415402243, 'baseline': 0.031557083112117065}\n",
      "{'name': 'top 3 match', 'correlation': 0.3738182393979192, 'baseline': 0.0881372192881959}\n",
      "{'name': 'top 5 match', 'correlation': 0.43500433118171405, 'baseline': 0.14561619209955198}\n",
      "{'name': 'top 5% match', 'correlation': 0.34707202801762277, 'baseline': 0.06557315971349}\n"
     ]
    }
   ],
   "source": [
    "key1, key2 = ('normal_A', iterations[-1], 'alpha'), ('uniform', iterations[-1], 'beta')\n",
    "print(key1, key2)\n",
    "for metric in metrics:\n",
    "    print(metric.eval_corr(dicts, key1, key2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('uniform', 98000, 'beta') embed256_beta\n",
      "{'name': 'top 1 match', 'correlation': 0.34697888432484797, 'baseline': 0.040349847710062316}\n",
      "{'name': 'top 3 match', 'correlation': 0.41936084798017903, 'baseline': 0.09972895185402521}\n",
      "{'name': 'top 5 match', 'correlation': 0.47952701632808936, 'baseline': 0.1557176255809838}\n",
      "{'name': 'top 5% match', 'correlation': 0.39109173722301394, 'baseline': 0.07727200752601038}\n"
     ]
    }
   ],
   "source": [
    "key1, key2 = ('uniform', iterations[-1], 'beta'), 'embed256_beta'\n",
    "print(key1, key2)\n",
    "for metric in metrics:\n",
    "    print(metric.eval_corr(dicts, key1, key2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('uniform', 98000, 'beta') IBM_beta\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'IBM_beta'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-2c394cb3d9a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_corr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/current_projects/NLP_research/AttentionResearch/AttentionDynamics/translation/utils.py\u001b[0m in \u001b[0;36meval_corr\u001b[0;34m(self, dicts, key1, key2)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# for each datapoints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0marr1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;31m# for each target word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'IBM_beta'"
     ]
    }
   ],
   "source": [
    "key1, key2 = ('uniform', iterations[-1], 'beta'), 'IBM_beta'\n",
    "print(key1, key2)\n",
    "for metric in metrics:\n",
    "    print(metric.eval_corr(dicts, key1, key2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
