{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "for dataset in ['iwslt14', 'multi30k']:\n",
    "    logs = pkl.load(open('data/{dataset}_logs.pkl'.format(dataset=dataset), 'rb'))\n",
    "\n",
    "    num_datapoints = len(logs['sequences'])\n",
    "\n",
    "    iterations = logs['normal_A'].keys()\n",
    "    dicts = logs['sequences']\n",
    "    for key in logs:\n",
    "        if key == 'sequences':\n",
    "            continue\n",
    "        for iteration in iterations:\n",
    "            for datapoint_idx in range(num_datapoints):\n",
    "                dicts[datapoint_idx][(key, iteration, 'alpha')] = logs[key][iteration][datapoint_idx]['alpha']\n",
    "                dicts[datapoint_idx][(key, iteration, 'beta')] = logs[key][iteration][datapoint_idx]['beta']\n",
    "                dicts[datapoint_idx]['split'] = logs[key][iteration][datapoint_idx]['split']\n",
    "    pkl.dump(dicts, open('data/{dataset}_logs_rz.pkl'.format(dataset=dataset), 'wb'))\n",
    "    \"\"\"\n",
    "from utils import *\n",
    "\n",
    "def max_acc_iter(name, metas):\n",
    "    max_acc = -1.0\n",
    "    max_acc_iter = None\n",
    "    for key_ in metas:\n",
    "        if key_[0] == name and key_[2] == 'val_acc':\n",
    "            if metas[key_] > max_acc:\n",
    "                max_acc = metas[key_]\n",
    "                max_acc_iter = key_[1]\n",
    "    return max_acc_iter\n",
    "\n",
    "def passing_idx(A1s, A2):\n",
    "    for i in range(len(A1s)):\n",
    "        if A1s[i] > A2:\n",
    "            return i\n",
    "    return None\n",
    "\n",
    "def corrs_iter(dicts, key1, keys2, corr_metric, reverse=False):\n",
    "    corrs = []\n",
    "    baselines = []\n",
    "    for key2 in keys2:\n",
    "        if reverse:\n",
    "                vals = corr_metric.eval_corr(dicts, key2, key1)\n",
    "        else:\n",
    "            vals = corr_metric.eval_corr(dicts, key1, key2)\n",
    "        corrs.append(vals['correlation'])\n",
    "        baselines.append(vals['baseline'])\n",
    "    return corrs, baselines\n",
    "\n",
    "def acc_iter(metas, keys):\n",
    "    accs = []\n",
    "    for key in keys:\n",
    "        accs.append(metas[key])\n",
    "    return accs\n",
    "\n",
    "def max_corr(dicts, key1, keys2, metric, reverse=False):\n",
    "    return max(corrs_iter(dicts, key1, keys2, metric, reverse=reverse)[0])\n",
    "\n",
    "def impute_beta(dicts, beta_matrix, key_name):\n",
    "    for item in dicts:\n",
    "        betas = []\n",
    "        for tok_trg in item['trg'][1:]:\n",
    "            beta = []\n",
    "            for tok_src in item['src']:\n",
    "                beta.append(beta_matrix[tok_src][tok_trg])\n",
    "            betas.append(beta)\n",
    "        betas = np.array(betas)\n",
    "        item[key_name] = betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'multi30k'\n",
    "dat = pkl.load(open('outputs/{dataset}_logs.pkl'.format(dataset=dataset), 'rb'))\n",
    "all_dicts = dat['data']\n",
    "subset = 'val'\n",
    "dicts = [d for d in all_dicts if d['split'] == 'val']\n",
    "iterations = sorted(list(set([key[1] for key in dat['metas']])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_beta = pkl.load(open('outputs/{dataset}embedding256translation.pkl'.format(dataset=dataset), 'rb'))\n",
    "impute_beta(dicts, embed_beta, 'embed_beta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = TopPercentMatch(p=5)\n",
    "normalA_iter = max_acc_iter('normal_A', dat['metas'])\n",
    "normalB_iter = max_acc_iter('normal_B', dat['metas'])\n",
    "uniform_iter = max_acc_iter('uniform', dat['metas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_alpha_key = ('normal_A', normalA_iter, 'alpha')\n",
    "gold_grad_key = ('normal_A', normalA_iter, 'grad')\n",
    "\n",
    "normal_keys = [('normal_B', iter_, 'alpha') for iter_ in iterations]\n",
    "acc_keys = [('normal_B', iter_, 'val_acc') for iter_ in iterations]\n",
    "\n",
    "alpha_corrs, alpha_baseline = corrs_iter(dicts, gold_alpha_key, normal_keys, metric)\n",
    "alpha_perfs = acc_iter(dat['metas'], acc_keys)\n",
    "\n",
    "avg_corr = np.array(alpha_corrs)\n",
    "avg_perf = np.array(alpha_perfs)\n",
    "baseline = alpha_baseline[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_unif_keys = [('uniform', iter_, 'beta') for iter_ in iterations]\n",
    "beta_corr_unif = max_corr(dicts, gold_alpha_key, beta_unif_keys, metric)\n",
    "beta_corr_grad = max_corr(dicts, gold_grad_key, beta_unif_keys, metric)\n",
    "beta_corr_px = max_corr(dicts, 'embed_beta', beta_unif_keys, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31019777503090235 0.3442521631644005 0.27058096415327565 0.07126081582200247 43.4487021013597 43.4487021013597 43.4487021013597 66.29171817058096\n"
     ]
    }
   ],
   "source": [
    "best_acc = dat['metas'][('normal_A', normalA_iter, 'val_acc')]\n",
    "idx_unif = passing_idx(avg_corr, beta_corr_unif)\n",
    "idx_grad = passing_idx(avg_corr, beta_corr_grad)\n",
    "idx_px = passing_idx(avg_corr, beta_corr_px)\n",
    "def print_perf(idx):\n",
    "    if idx is None:\n",
    "        return None\n",
    "    else:\n",
    "        return avg_perf[idx]\n",
    "print(beta_corr_unif, beta_corr_px, beta_corr_grad, baseline, print_perf(idx_unif), print_perf(idx_px), print_perf(idx_grad), best_acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('normal_A', 98000, 'alpha') ('normal_B', 98000, 'beta')\n",
      "{'name': 'top 1 match', 'correlation': 0.4906809735378769, 'baseline': 0.029517236240347983}\n",
      "{'name': 'top 3 match', 'correlation': 0.630424455807975, 'baseline': 0.08793696034872998}\n",
      "{'name': 'top 5 match', 'correlation': 0.6835303322435521, 'baseline': 0.1448337850802433}\n",
      "{'name': 'top 5% match', 'correlation': 0.6016337403712707, 'baseline': 0.06422257616825476}\n"
     ]
    }
   ],
   "source": [
    "# metrics.append(SpearmanRankCorr()) comment out because this takes a lot of time to evaluate\n",
    "key1, key2 = ('normal_A', normalA_iter, 'alpha'), ('normal_B', normalB_iter, 'beta')\n",
    "print(key1, key2)\n",
    "for metric in metrics:\n",
    "    print(metric.eval_corr(dicts, key1, key2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('normal_A', 98000, 'alpha') ('uniform', 98000, 'beta')\n",
      "{'name': 'top 1 match', 'correlation': 0.26383882415402243, 'baseline': 0.031557083112117065}\n",
      "{'name': 'top 3 match', 'correlation': 0.3738182393979192, 'baseline': 0.0881372192881959}\n",
      "{'name': 'top 5 match', 'correlation': 0.43500433118171405, 'baseline': 0.14561619209955198}\n",
      "{'name': 'top 5% match', 'correlation': 0.34707202801762277, 'baseline': 0.06557315971349}\n"
     ]
    }
   ],
   "source": [
    "key1, key2 = ('normal_A', iterations[-1], 'alpha'), ('uniform', iterations[-1], 'beta')\n",
    "print(key1, key2)\n",
    "for metric in metrics:\n",
    "    print(metric.eval_corr(dicts, key1, key2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('uniform', 98000, 'beta') embed256_beta\n",
      "{'name': 'top 1 match', 'correlation': 0.34697888432484797, 'baseline': 0.040349847710062316}\n",
      "{'name': 'top 3 match', 'correlation': 0.41936084798017903, 'baseline': 0.09972895185402521}\n",
      "{'name': 'top 5 match', 'correlation': 0.47952701632808936, 'baseline': 0.1557176255809838}\n",
      "{'name': 'top 5% match', 'correlation': 0.39109173722301394, 'baseline': 0.07727200752601038}\n"
     ]
    }
   ],
   "source": [
    "key1, key2 = ('uniform', iterations[-1], 'beta'), 'embed256_beta'\n",
    "print(key1, key2)\n",
    "for metric in metrics:\n",
    "    print(metric.eval_corr(dicts, key1, key2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('uniform', 98000, 'beta') IBM_beta\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'IBM_beta'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-2c394cb3d9a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_corr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/current_projects/NLP_research/AttentionResearch/AttentionDynamics/translation/utils.py\u001b[0m in \u001b[0;36meval_corr\u001b[0;34m(self, dicts, key1, key2)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# for each datapoints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0marr1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;31m# for each target word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'IBM_beta'"
     ]
    }
   ],
   "source": [
    "key1, key2 = ('uniform', iterations[-1], 'beta'), 'IBM_beta'\n",
    "print(key1, key2)\n",
    "for metric in metrics:\n",
    "    print(metric.eval_corr(dicts, key1, key2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
