{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "for dataset in ['iwslt14', 'multi30k']:\n",
    "    logs = pkl.load(open('data/{dataset}_logs.pkl'.format(dataset=dataset), 'rb'))\n",
    "\n",
    "    num_datapoints = len(logs['sequences'])\n",
    "\n",
    "    iterations = logs['normal_A'].keys()\n",
    "    dicts = logs['sequences']\n",
    "    for key in logs:\n",
    "        if key == 'sequences':\n",
    "            continue\n",
    "        for iteration in iterations:\n",
    "            for datapoint_idx in range(num_datapoints):\n",
    "                dicts[datapoint_idx][(key, iteration, 'alpha')] = logs[key][iteration][datapoint_idx]['alpha']\n",
    "                dicts[datapoint_idx][(key, iteration, 'beta')] = logs[key][iteration][datapoint_idx]['beta']\n",
    "                dicts[datapoint_idx]['split'] = logs[key][iteration][datapoint_idx]['split']\n",
    "    pkl.dump(dicts, open('data/{dataset}_logs_rz.pkl'.format(dataset=dataset), 'wb'))\n",
    "    \"\"\"\n",
    "from utils import *\n",
    "\n",
    "def max_acc_iter(name, metas):\n",
    "    max_acc = -1.0\n",
    "    max_acc_iter = None\n",
    "    for key_ in metas:\n",
    "        if key_[0] == name and 'test' in key_[2]:\n",
    "            if metas[key_] > max_acc:\n",
    "                max_acc = metas[key_]\n",
    "                max_acc_iter = key_[1]\n",
    "    return max_acc_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Furd'\n",
    "dat = pkl.load(open('outputs/{dataset}_logs.pkl'.format(dataset=dataset), 'rb'))\n",
    "all_dicts = dat['data']\n",
    "subset = 'val'\n",
    "dicts = [d for d in all_dicts if d['split'] == subset]\n",
    "iterations = sorted(list(set([key[1] for key in dat['metas']])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import TopKMatch, TopPercentMatch, SpearmanRankCorr\n",
    "metrics = [TopKMatch(k=1), TopKMatch(k=3), TopKMatch(k=5), TopPercentMatch(p=5)]\n",
    "normalA_iter = max_acc_iter('normal_A', dat['metas'])\n",
    "normalB_iter = max_acc_iter('normal_B', dat['metas'])\n",
    "uniform_iter = max_acc_iter('uniform', dat['metas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('normal_A', 3000, 'alpha') ('normal_B', 3999, 'beta')\n",
      "{'name': 'top 1 match', 'correlation': 0.059113300492610835, 'baseline': 0.07600281491907107}\n",
      "{'name': 'top 3 match', 'correlation': 0.16819141449683322, 'baseline': 0.21463757916959889}\n",
      "{'name': 'top 5 match', 'correlation': 0.2660098522167488, 'baseline': 0.32371569317382126}\n",
      "{'name': 'top 5% match', 'correlation': 0.0752990851513019, 'baseline': 0.0781140042223786}\n"
     ]
    }
   ],
   "source": [
    "# metrics.append(SpearmanRankCorr()) comment out because this takes a lot of time to evaluate\n",
    "key1, key2 = ('normal_A', normalA_iter, 'alpha'), ('normal_B', normalB_iter, 'beta')\n",
    "print(key1, key2)\n",
    "for metric in metrics:\n",
    "    print(metric.eval_corr(dicts, key1, key2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('normal_A', 3000, 'alpha') ('uniform', 3000, 'beta')\n",
      "{'name': 'top 1 match', 'correlation': 0.03518648838845883, 'baseline': 0.07178043631245602}\n",
      "{'name': 'top 3 match', 'correlation': 0.12526389866291343, 'baseline': 0.199155524278677}\n",
      "{'name': 'top 5 match', 'correlation': 0.25193525686136525, 'baseline': 0.3286418015482055}\n",
      "{'name': 'top 5% match', 'correlation': 0.045038705137227304, 'baseline': 0.09429978888106967}\n"
     ]
    }
   ],
   "source": [
    "key1, key2 = ('normal_A', normalA_iter, 'alpha'), ('uniform', uniform_iter, 'beta')\n",
    "print(key1, key2)\n",
    "for metric in metrics:\n",
    "    print(metric.eval_corr(dicts, key1, key2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('uniform', 3000, 'beta') logistics_beta\n",
      "{'name': 'top 1 match', 'correlation': 0.09078114004222379, 'baseline': 0.08515130190007038}\n",
      "{'name': 'top 3 match', 'correlation': 0.2674173117522871, 'baseline': 0.21604503870513722}\n",
      "{'name': 'top 5 match', 'correlation': 0.4560168895144265, 'baseline': 0.3645320197044335}\n",
      "{'name': 'top 5% match', 'correlation': 0.11611541168191415, 'baseline': 0.09218859957776214}\n"
     ]
    }
   ],
   "source": [
    "key1, key2 = ('uniform', uniform_iter, 'beta'), 'logistics_beta'\n",
    "print(key1, key2)\n",
    "for metric in metrics:\n",
    "    print(metric.eval_corr(dicts, key1, key2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
